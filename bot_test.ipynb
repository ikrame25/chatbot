{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meet Monty The Professional Python Chatbot\n",
    "\n",
    "[![chatbot](img/chatbot.png)](img/chatbot.png)\n",
    "\n",
    "**The Problem:** As users have become used to the fast-paced microwave lifestyle, their immediate need and attention are of utmost important. Users will, leave a website if they cannot get their questions answered.\n",
    "\n",
    "**The Question:** What can we do satisfy the customers immediate needs?\n",
    "\n",
    "**The Solution:** Chatbot! Websites today isn't complete without a chatbot companion. When users are in immediate need of an answer they can simply ask their question to the chatbot to get an immediate response.\n",
    "<br/>\n",
    "## Purpose:\n",
    "The purpose of this chatbot is to have a an **easy to implement chatbot* with only a csv containing questions and response**. This can be used to enhance customer experience with the frequently asked questions and answer immediately on any website. \n",
    "\n",
    "## Benefits:\n",
    "This will benefit the company with an immediate customer engagement, effeciency and lower overhead on employee cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import all dependencies\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from attention_decoder import AttentionDecoder\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![chatbot](img/cogs.jpeg)](img/cogs.jpeg)\n",
    "\n",
    "## COGS:\n",
    "The following functions are the COGS in making this implemenation smooth. These helper functions and please read each description and code for detail information on the purpose of each function. These cogs are literally what makes monty ticks. (pun intended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return all sentences from the 2 list (q&a)\n",
    "def return_sents(df_col1, df_col2):\n",
    "    return [sent for sent in df.question] + [sent for sent in df.answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return unique words from list of sentences\n",
    "def return_unique_words(all_sents):\n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    all_words = [words.split() for words in all_sents] \n",
    "    word_list = [word.lower() for sublist in all_words for word in sublist]\n",
    "    word_list = [word.translate(table) for word in word_list] \n",
    "\n",
    "# *** removed stemming to enhance Monty's reponse    \n",
    "#    word_list = [ps.stem(word) for word in word_list]\n",
    "    return list(set(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a dataframe of words from 2 list, this data frame is used as a form of hash table\n",
    "# key would be the index and the value would be the word\n",
    "def df_to_df(df_col1, df_col2):\n",
    "    all_sent = return_sents(df_col1, df_col2)\n",
    "    word_list = return_unique_words(all_sent)\n",
    "    word_list.insert(0, ' ')\n",
    "    t_df = pd.DataFrame()\n",
    "    t_df['word'] = word_list\n",
    "    t_df['idx'] = t_df.index\n",
    "    return t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return unique words from list of sentences\n",
    "def return_unique_words_single(sent):\n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    all_words = sent.split()\n",
    "    word_list = [word.lower() for word in all_words]\n",
    "    word_list = [word.translate(table) for word in word_list] \n",
    "\n",
    "# *** removed stemming to enhance Monty's reponse    \n",
    "#    word_list = [ps.stem(word) for word in word_list]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function takes the sentences and the hash table of word index and returns the array \n",
    "# equivalent index of the words in each sentence\n",
    "def word_to_array(sents, t_df):\n",
    "    l = []\n",
    "    l2 = []\n",
    "    for sent in sents:\n",
    "        b = []\n",
    "        a = return_unique_words_single(sent)\n",
    "        for w in a:\n",
    "            try:\n",
    "                b.append(t_df.loc[t_df.word == w, 'idx'].iloc[0])\n",
    "            except:\n",
    "                b.append(0)\n",
    "        l.append(a)\n",
    "        l2.append(b)\n",
    "    return l, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decodes the array back into string so humans can understand what Monty is saying\n",
    "def array_to_string(ar):\n",
    "    c = [t_df.loc[t_df.idx == i, 'word'].iloc[0] for i in ar]\n",
    "    s = ' '.join(c)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the array sequence\n",
    "def one_hot_encode(sequence, n_unique):\n",
    "    encoding = list()\n",
    "    for value in sequence:\n",
    "        vector = [0 for _ in range(n_unique)]\n",
    "        vector[value] = 1\n",
    "        encoding.append(vector)\n",
    "    return array(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode a one hot encoded array sequence\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [argmax(vector) for vector in encoded_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the X & y into one hot format and reshape it into proper input shape\n",
    "def transform_xy(sequence_in, sequence_out, n_features):\n",
    "    X = one_hot_encode(sequence_in, n_features)\n",
    "    y = one_hot_encode(sequence_out, n_features)\n",
    "    X = X.reshape((1, X.shape[0], X.shape[1]))\n",
    "    y = y.reshape((1, y.shape[0], y.shape[1]))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for user interaction purposes Monty breaks down each word from each sentence and looks\n",
    "# up the equivalent \n",
    "def sent_to_array(sent, t_df):\n",
    "    a = []\n",
    "    b = []\n",
    "    a = return_unique_words_single(sent)\n",
    "    for w in a:\n",
    "        try:\n",
    "            b.append(t_df.loc[t_df.word == w, 'idx'].iloc[0])\n",
    "        except:\n",
    "            b.append(0)\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for user interaction purposes Monty breaks down each word from the user input and encode\n",
    "# and shapes it into something the model can use to predict\n",
    "def transform_x(sequence_in, n_features):\n",
    "    X = one_hot_encode(sequence_in, n_features)\n",
    "    X = X.reshape((1, X.shape[0], X.shape[1]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ease of use this function was created to make it easier to interact with Monty\n",
    "# it takes the user input and returns a response\n",
    "def get_response(sent, t_df):\n",
    "    w, q = sent_to_array(sent, t_df)\n",
    "    q_pad = pad_sequences([q], maxlen=max_length, padding='post')\n",
    "    X2 = transform_x(q_pad[0], n_features)\n",
    "    yhat2 = model.predict(X2, verbose=0)\n",
    "    return array_to_string(one_hot_decode(yhat2[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of COGS and the start of Monty's professional career.\n",
    "[![chatbot](img/start.png)](img/start.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello</td>\n",
       "      <td>HI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey</td>\n",
       "      <td>Hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hi</td>\n",
       "      <td>Hey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how are you?</td>\n",
       "      <td>good, you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how is it going?</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>good</td>\n",
       "      <td>same here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>great</td>\n",
       "      <td>that is good to hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what color is the sky</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bye</td>\n",
       "      <td>bye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                question                answer\n",
       "0                  hello                    HI\n",
       "1                    hey                 Hello\n",
       "2                     hi                   Hey\n",
       "3           how are you?            good, you?\n",
       "4       how is it going?                 great\n",
       "5                   good             same here\n",
       "6                  great  that is good to hear\n",
       "7  what color is the sky                  blue\n",
       "8                    bye                   bye\n",
       "9                goodbye               goodbye"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv into pandas dataframe\n",
    "ps = PorterStemmer()\n",
    "df = pd.read_csv('qna.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>me</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>else</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interesting</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>too</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  idx\n",
       "0                 0\n",
       "1           me    1\n",
       "2         else    2\n",
       "3  interesting    3\n",
       "4          too    4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an index of words, please note that index 0 is set to an empty space\n",
    "t_df = df_to_df(df.question, df.answer)\n",
    "t_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question word list:\n",
      " [['hello'], ['hey'], ['hi'], ['how', 'are', 'you'], ['how', 'is', 'it', 'going']] \n",
      "\n",
      " Question array list:\n",
      " [[58], [56], [63], [47, 132, 119], [47, 45, 96, 125]] \n",
      "\n",
      "\n",
      "Answer word list:\n",
      " [['hi'], ['hello'], ['hey'], ['good', 'you'], ['great']] \n",
      "\n",
      " Answer array list:\n",
      " [[63], [58], [56], [79, 119], [8]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform questions & answers to a word array and a sequence array\n",
    "q_list, q_as_array = word_to_array(df.question, t_df)\n",
    "a_list, a_as_array = word_to_array(df.answer, t_df)\n",
    "\n",
    "# print the first 5 array\n",
    "print('Question word list:\\n', q_list[:5], '\\n'*2,'Question array list:\\n', q_as_array[:5], '\\n'*2)\n",
    "print('Answer word list:\\n', a_list[:5],'\\n'*2, 'Answer array list:\\n', a_as_array[:5],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monty's requirement:\n",
    "Monty cannot understand human words, it does understand numbers, what we created above was a translator. Each word is tied to a number. So a each word in a sentence is translated to it's number equivalent so that Monty can understand.\n",
    "\n",
    "## The Model Explained:\n",
    "\"The Encoding/decoding model of communication was first developed by cultural studies scholar Stuart Hall in 1973. Titled 'Encoding and Decoding in the Television Discourse', Hall's essay offers a theoretical approach of how media messages are produced, disseminated, and interpreted.[1] As an important member of the Birmingham School of Cultural Studies, Hall had a major influence on media studies. His model claims that television and other media audiences are presented with messages that are decoded, or interpreted in different ways depending on an individual's cultural background, economic standing, and personal experiences. In contrast to other media theories that disempower audiences, Hall proposed that audience members can play an active role in decoding messages as they rely on their own social contexts, and might be capable of changing messages themselves through collective action. In simpler terms, encoding/decoding is the translation of a message that is easily understood. When you decode a message, you extract the meaning of that message in ways that make sense to you. Decoding has both verbal and non-verbal forms of communication: Decoding behavior without using words means observing body language and its associated emotions. For example, some body language signs for when someone is upset, angry, or stressed would be a use of excessive hand/arm movements, red in the face, crying, and even sometimes silence. Sometimes when someone is trying to get a message across to someone, the message can be interpreted differently from person to person. Decoding is all about the understanding of what someone already knows, based on the information given throughout the message being received. Whether there is a large audience or exchanging a message to one person, decoding is the process of obtaining, absorbing, understanding, and sometimes using the information that was given throughout a verbal or non-verbal message.\" ~ Wikipedia (https://en.wikipedia.org/wiki/Encoding/decoding_model_of_communication)\n",
    "\n",
    "[![chatbot](img/seq2seq.png)](img/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size:  137\n",
      "Number of features:  137 \n",
      "\n",
      "Max Length of Question:  8\n",
      "Max Length of Answer:  9\n",
      "Max Padded Length:  12\n"
     ]
    }
   ],
   "source": [
    "# use the length of the index of the word matrix as the vocabulary size\n",
    "vocab_size = len(t_df)\n",
    "print('Vocab Size: ', vocab_size)\n",
    "\n",
    "# set max features(vocab size) equal to vocab size\n",
    "n_features = vocab_size\n",
    "print('Number of features: ', n_features, '\\n')\n",
    "\n",
    "# find the max length of question & answer\n",
    "max_q_l = len(max(q_as_array,key=len))\n",
    "max_a_l = len(max(a_as_array,key=len))\n",
    "max_l = max(max_q_l, max_a_l)\n",
    "print('Max Length of Question: ', max_q_l)\n",
    "print('Max Length of Answer: ', max_a_l)\n",
    "\n",
    "# set max length equal to max length + 3 to ensure ample padding\n",
    "max_length = max_l + 3\n",
    "print('Max Padded Length: ', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded questions array:\n",
      " [[ 58   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 56   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 63   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 47 132 119   0   0   0   0   0   0   0   0   0]\n",
      " [ 47  45  96 125   0   0   0   0   0   0   0   0]\n",
      " [ 79   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  8   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 33  82  45  49  94   0   0   0   0   0   0   0]\n",
      " [  9   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 14   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "Padded answers array:\n",
      " [[ 63   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 58   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 56   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 79 119   0   0   0   0   0   0   0   0   0   0]\n",
      " [  8   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [110  39   0   0   0   0   0   0   0   0   0   0]\n",
      " [100  45  79  93  32   0   0   0   0   0   0   0]\n",
      " [ 38   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  9   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 14   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# using the keras function pad_sequences, we pad with the default value of 0 up to the max length of any q&a\n",
    "\n",
    "# pad questions to max length\n",
    "padded_q_docs = pad_sequences(q_as_array, maxlen=max_length, padding='post')\n",
    "print('Padded questions array:\\n', padded_q_docs[:10])\n",
    "\n",
    "# pad answers to max length\n",
    "padded_a_docs = pad_sequences(a_as_array, maxlen=max_length, padding='post')\n",
    "print('\\nPadded answers array:\\n', padded_a_docs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(150, input_shape=(max_length, n_features), return_sequences=True))\n",
    "model.add(AttentionDecoder(150, n_features))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [01:17<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# train the model for half the length for number of features\n",
    "for a in tqdm(range(0, n_features//2)):\n",
    "    for n in range(0, len(padded_q_docs)):\n",
    "        # transform xy\n",
    "        X,y = transform_xy(padded_q_docs[n], padded_a_docs[n], n_features)\n",
    "        \n",
    "        # fit model for one epoch on this sequence\n",
    "        model.fit(X, y, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set #12\n",
      "Question Array: [33, 45, 112, 124, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : what is your name                 \n",
      "\n",
      "Expected Response Array: [95, 135, 12, 119, 27, 119, 132, 52, 68, 0, 0, 0] \n",
      "Expected Response: i cannot tell you because you are a stranger       \n",
      "\n",
      "Predicted Response Array: [95, 135, 12, 119, 27, 119, 132, 52, 68, 0, 0, 0] \n",
      "Predicted Response: i cannot tell you because you are a stranger       \n",
      "\n",
      "Set #13\n",
      "Question Array: [47, 134, 132, 119, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : how old are you                 \n",
      "\n",
      "Expected Response Array: [100, 45, 99, 26, 119, 40, 52, 11, 0, 0, 0, 0] \n",
      "Expected Response: that is not something you ask a lady         \n",
      "\n",
      "Predicted Response Array: [100, 45, 99, 26, 119, 40, 52, 11, 0, 0, 0, 0] \n",
      "Predicted Response: that is not something you ask a lady         \n",
      "\n",
      "Set #14\n",
      "Question Array: [33, 73, 119, 73, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : what do you do                 \n",
      "\n",
      "Expected Response Array: [76, 127, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: professional chatbox                     \n",
      "\n",
      "Predicted Response Array: [76, 127, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: professional chatbox                     \n",
      "\n",
      "Total Training Accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "# print 3 sets of questions, expected response and predicted response\n",
    "for n in range(12, 15):\n",
    "    X,y = transform_xy(padded_q_docs[n], padded_a_docs[n], n_features)\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    print('Set #{}'.format(n))\n",
    "    print('Question Array:', one_hot_decode(X[0]), '\\nQuestion :', array_to_string(one_hot_decode(X[0])), '\\n')\n",
    "    print('Expected Response Array:', one_hot_decode(y[0]), '\\nExpected Response:', array_to_string(one_hot_decode(y[0])), '\\n')\n",
    "    print('Predicted Response Array:', one_hot_decode(yhat[0]), '\\nPredicted Response:', array_to_string(one_hot_decode(yhat[0])), '\\n')\n",
    "\n",
    "# print accuracy of model\n",
    "total, correct = len(padded_q_docs), 0\n",
    "for n in range(total):\n",
    "    X,y = transform_xy(padded_q_docs[n], padded_a_docs[n], n_features)\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    if array_equal(one_hot_decode(y[0]), one_hot_decode(yhat[0])):\n",
    "        correct += 1\n",
    "print('Total Training Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  hello \n",
      "Monty:  hi                      \n",
      "User:  how goes it? \n",
      "Monty:  great                      \n",
      "User:  what do you do for work? \n",
      "Monty:  anything you can think of              \n",
      "User:  can you tell me your name? \n",
      "Monty:  i cannot tell you because you are a stranger      \n",
      "User:  you're a mean robot \n",
      "Monty:  hahahahaha                      \n",
      "User:  bye \n",
      "Monty:  goodbye                      \n"
     ]
    }
   ],
   "source": [
    "# create\n",
    "sent0 = \"hello\"\n",
    "sent1 = \"how goes it?\"\n",
    "sent2 = \"what do you do for work?\"\n",
    "sent3 = \"can you tell me your name?\"\n",
    "sent4 = \"you're a mean robot\"\n",
    "sent5 = \"bye\"\n",
    "\n",
    "for n in range(0, 6):\n",
    "    print('User: ', eval('sent'+str(n)), '\\nMonty: ', get_response(eval('sent'+str(n)), t_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![chatbot](img/thankyou.jpg)](img/thankyou.jpg)\n",
    "# ... for chatting with Monty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
