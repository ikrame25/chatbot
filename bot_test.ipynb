{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meet Monty The Professional Python Chatbot\n",
    "\n",
    "[![chatbot](img/chatbot.png)](img/chatbot.png)\n",
    "\n",
    "## The problem:\n",
    "As online users have become used to the fast-paced microwave lifestyle, their immediate need and attention are of utmost important. According to research done by Neilsen Norman Group “Users often leave Web pages in 10–20 seconds, but pages with a clear value proposition can hold people's attention for much longer.” (Nielsen 2011) \n",
    "\n",
    "[![weibull.png](img/weibull.png)](img/weibull.png)\n",
    "\n",
    "“It's clear from the chart that the first 10 seconds of the page visit are critical for users' decision to stay or leave. The probability of leaving is very high during these first few seconds because users are extremely skeptical, having suffered countless poorly designed web pages in the past. People know that most web pages are useless, and they behave accordingly to avoid wasting more time than absolutely necessary on bad pages.” (Nielsen 2011)\n",
    "\n",
    "## The question:\n",
    "So what can we do engage the users in a way that will not leave them skeptical or give the impression that the website is poorly designed?\n",
    "\n",
    "## The solution:\n",
    "A chatbot! Yes, “chatbots are beneficial for both parties: developing chatbots is cheaper than training and hiring human customer service agents for the company, and customers often prefer a brisk mobile interaction over talking with someone in person or with the call center. Consider this statistic from Gartner, that artificial intelligence will amount for 85% of customer relationships by 2020.” (Morgan 2017)\n",
    "\n",
    "## Purpose:\n",
    "The purpose of this chatbot is to have a an **easy to implement chatbot that only uses a csv containing questions and response**. This can be used to enhance customer experience with the frequently asked questions and answer immediately on any website. This model can be quickly implemented for any online business.\n",
    "\n",
    "## Benefits:\n",
    "This will benefit the company with an immediate customer engagement, as shown on the diagram after the first 20 seconds users are more likely to stay long term. In addition this will add effeciency and lower overhead on employee cost for the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import all dependencies\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from attention_decoder import AttentionDecoder\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![chatbot](img/cogs.jpeg)](img/cogs.jpeg)\n",
    "\n",
    "## COGS:\n",
    "The following functions are the COGS in making this implemenation smooth. These helper functions and please read each description and code for detail information on the purpose of each function. These cogs are literally what makes monty ticks. (pun intended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return all sentences from the 2 list (q&a)\n",
    "def return_sents(df_col1, df_col2):\n",
    "    return [sent for sent in df_col1] + [sent for sent in df_col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return unique words from list of sentences\n",
    "def return_unique_words(all_sents):\n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    all_words = [words.split() for words in all_sents] \n",
    "    word_list = [word.lower() for sublist in all_words for word in sublist]\n",
    "    word_list = [word.translate(table) for word in word_list] \n",
    "\n",
    "# *** removed stemming to enhance Monty's reponse    \n",
    "#    word_list = [ps.stem(word) for word in word_list]\n",
    "    return list(set(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a dataframe of words from 2 list, this data frame is used as a form of hash table\n",
    "# key would be the index and the value would be the word\n",
    "def df_to_df(df_col1, df_col2):\n",
    "    all_sent = return_sents(df_col1, df_col2)\n",
    "    word_list = return_unique_words(all_sent)\n",
    "    word_list.insert(0, ' ')\n",
    "    t_df = pd.DataFrame()\n",
    "    t_df['word'] = word_list\n",
    "    t_df['idx'] = t_df.index\n",
    "    return t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return unique words from list of sentences\n",
    "def return_unique_words_single(sent):\n",
    "    table = str.maketrans({key: None for key in string.punctuation})\n",
    "    all_words = sent.split()\n",
    "    word_list = [word.lower() for word in all_words]\n",
    "    word_list = [word.translate(table) for word in word_list] \n",
    "\n",
    "# *** removed stemming to enhance Monty's reponse    \n",
    "#    word_list = [ps.stem(word) for word in word_list]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function takes the sentences and the hash table of word index and returns the array \n",
    "# equivalent index of the words in each sentence\n",
    "def word_to_array(sents, t_df):\n",
    "    l = []\n",
    "    l2 = []\n",
    "    for sent in sents:\n",
    "        b = []\n",
    "        a = return_unique_words_single(sent)\n",
    "        for w in a:\n",
    "            try:\n",
    "                b.append(t_df.loc[t_df.word == w, 'idx'].iloc[0])\n",
    "            except:\n",
    "                b.append(0)\n",
    "        l.append(a)\n",
    "        l2.append(b)\n",
    "    return l, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decodes the array back into string so humans can understand what Monty is saying\n",
    "def array_to_string(ar, t_df):\n",
    "    c = [t_df.loc[t_df.idx == i, 'word'].iloc[0] for i in ar]\n",
    "    s = ' '.join(c)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the array sequence\n",
    "def one_hot_encode(sequence, n_unique):\n",
    "    encoding = list()\n",
    "    for value in sequence:\n",
    "        vector = [0 for _ in range(n_unique)]\n",
    "        vector[value] = 1\n",
    "        encoding.append(vector)\n",
    "    return array(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode a one hot encoded array sequence\n",
    "def one_hot_decode(encoded_seq):\n",
    "    return [argmax(vector) for vector in encoded_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the X & y into one hot format and reshape it into proper input shape\n",
    "def transform_xy(sequence_in, sequence_out, n_features):\n",
    "    X = one_hot_encode(sequence_in, n_features)\n",
    "    y = one_hot_encode(sequence_out, n_features)\n",
    "    X = X.reshape((1, X.shape[0], X.shape[1]))\n",
    "    y = y.reshape((1, y.shape[0], y.shape[1]))\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for user interaction purposes Monty breaks down each word from each sentence and looks\n",
    "# up the equivalent \n",
    "def sent_to_array(sent, t_df):\n",
    "    a = []\n",
    "    b = []\n",
    "    a = return_unique_words_single(sent)\n",
    "    for w in a:\n",
    "        try:\n",
    "            b.append(t_df.loc[t_df.word == w, 'idx'].iloc[0])\n",
    "        except:\n",
    "            b.append(0)\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for user interaction purposes Monty breaks down each word from the user input and encode\n",
    "# and shapes it into something the model can use to predict\n",
    "def transform_x(sequence_in, n_features):\n",
    "    X = one_hot_encode(sequence_in, n_features)\n",
    "    X = X.reshape((1, X.shape[0], X.shape[1]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ease of use this function was created to make it easier to interact with Monty\n",
    "# it takes the user input and returns a response\n",
    "def get_response(sent, t_df, max_length, n_features, model):\n",
    "    w, q = sent_to_array(sent, t_df)\n",
    "    q_pad = pad_sequences([q], maxlen=max_length, padding='post')\n",
    "    X2 = transform_x(q_pad[0], n_features)\n",
    "    yhat2 = model.predict(X2, verbose=0)\n",
    "    return array_to_string(one_hot_decode(yhat2[0]), t_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of COGS and the start of Monty's professional career.\n",
    "[![chatbot](img/start.png)](img/start.png)\n",
    "\n",
    "## Monty's requirement:\n",
    "Monty cannot understand human words, however Monty does understand numbers, lucky for us Monty comes with a translator, it's part of his COGS function listed above. The translator works as it convert each word to a specific index number much like a hash table, key : value mapping.\n",
    "\n",
    "[![chatbot](img/monty.png)](img/monty.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hello</td>\n",
       "      <td>HI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey</td>\n",
       "      <td>Hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hi</td>\n",
       "      <td>Hey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how are you?</td>\n",
       "      <td>good, you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how is it going?</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>good</td>\n",
       "      <td>same here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>great</td>\n",
       "      <td>that is good to hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what color is the sky</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bye</td>\n",
       "      <td>bye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>goodbye</td>\n",
       "      <td>goodbye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                question                answer\n",
       "0                  hello                    HI\n",
       "1                    hey                 Hello\n",
       "2                     hi                   Hey\n",
       "3           how are you?            good, you?\n",
       "4       how is it going?                 great\n",
       "5                   good             same here\n",
       "6                  great  that is good to hear\n",
       "7  what color is the sky                  blue\n",
       "8                    bye                   bye\n",
       "9                goodbye               goodbye"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv into pandas dataframe\n",
    "ps = PorterStemmer()\n",
    "df = pd.read_csv('qna.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>something</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>well</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interesting</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  idx\n",
       "0                 0\n",
       "1       single    1\n",
       "2    something    2\n",
       "3         well    3\n",
       "4  interesting    4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an index of words, please note that index 0 is set to an empty space\n",
    "t_df = df_to_df(df.question, df.answer)\n",
    "t_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question word list:\n",
      " [['hello'], ['hey'], ['hi'], ['how', 'are', 'you'], ['how', 'is', 'it', 'going']] \n",
      "\n",
      " Question array list:\n",
      " [[82], [37], [22], [52, 100, 61], [52, 54, 6, 66]] \n",
      "\n",
      "\n",
      "Answer word list:\n",
      " [['hi'], ['hello'], ['hey'], ['good', 'you'], ['great']] \n",
      "\n",
      " Answer array list:\n",
      " [[22], [82], [37], [77, 61], [84]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform questions & answers to a word array and a sequence array\n",
    "# this is our translator so that monty will understand what we're saying\n",
    "q_list, q_as_array = word_to_array(df.question, t_df)\n",
    "a_list, a_as_array = word_to_array(df.answer, t_df)\n",
    "\n",
    "# print the first 5 array\n",
    "print('Question word list:\\n', q_list[:5], '\\n'*2,'Question array list:\\n', q_as_array[:5], '\\n'*2)\n",
    "print('Answer word list:\\n', a_list[:5],'\\n'*2, 'Answer array list:\\n', a_as_array[:5],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size:  137\n",
      "Number of features:  137 \n",
      "\n",
      "Max Length of Question:  8\n",
      "Max Length of Answer:  9\n",
      "Max Padded Length:  12\n"
     ]
    }
   ],
   "source": [
    "# use the length of the index of the word matrix as the vocabulary size\n",
    "vocab_size = len(t_df)\n",
    "print('Vocab Size: ', vocab_size)\n",
    "\n",
    "# set max features(vocab size) equal to vocab size\n",
    "n_features = vocab_size\n",
    "print('Number of features: ', n_features, '\\n')\n",
    "\n",
    "# find the max length of question & answer\n",
    "max_q_l = len(max(q_as_array,key=len))\n",
    "max_a_l = len(max(a_as_array,key=len))\n",
    "max_l = max(max_q_l, max_a_l)\n",
    "print('Max Length of Question: ', max_q_l)\n",
    "print('Max Length of Answer: ', max_a_l)\n",
    "\n",
    "# set max length equal to max length + 3 to ensure ample padding\n",
    "max_length = max_l + 3\n",
    "print('Max Padded Length: ', max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![chatbot](img/limit.jpg)](img/limit.jpg)\n",
    "\n",
    "## Monty's Limit:\n",
    "Monty, like human beings has limits.\n",
    "\n",
    "1. He can only respond with what you teach him. His knowledge is limited to his vocab size, meaning if you teach him 137 words, he only knows 137 words. His vocabulary is derived from the csv file.\n",
    "2. User can only ask & Monty can only respond to the maximum padded length. This is determined by the longest question or answer/response plus a padding. In this example we used 3 as the padding amount.\n",
    "3. Monty's learning speed/rate is determined by more so by the maximum length of a sentence and the vocabulary size than the overall document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded questions array:\n",
      " [[ 82   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 37   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 22   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 52 100  61   0   0   0   0   0   0   0   0   0]\n",
      " [ 52  54   6  66   0   0   0   0   0   0   0   0]\n",
      " [ 77   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 84   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 98 111  54  60   8   0   0   0   0   0   0   0]\n",
      " [103   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 88   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "Padded answers array:\n",
      " [[ 22   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 82   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 37   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 77  61   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 84   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 80 132   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 26  54  77 117  39   0   0   0   0   0   0   0]\n",
      " [120   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [103   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 88   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# using the keras function pad_sequences, we pad with the default value of 0 up to the max length of any q&a\n",
    "\n",
    "# pad questions to max length\n",
    "padded_q_docs = pad_sequences(q_as_array, maxlen=max_length, padding='post')\n",
    "print('Padded questions array:\\n', padded_q_docs[:10])\n",
    "\n",
    "# pad answers to max length\n",
    "padded_a_docs = pad_sequences(a_as_array, maxlen=max_length, padding='post')\n",
    "print('\\nPadded answers array:\\n', padded_a_docs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 12, 150)           172800    \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 12, 137)           324906    \n",
      "=================================================================\n",
      "Total params: 497,706\n",
      "Trainable params: 497,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(150, input_shape=(max_length, n_features), return_sequences=True))\n",
    "model.add(AttentionDecoder(150, n_features))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model Explained:\n",
    "\"The Encoding/decoding model of communication was first developed by cultural studies scholar Stuart Hall in 1973. Titled 'Encoding and Decoding in the Television Discourse', Hall's essay offers a theoretical approach of how media messages are produced, disseminated, and interpreted.[1] As an important member of the Birmingham School of Cultural Studies, Hall had a major influence on media studies. His model claims that television and other media audiences are presented with messages that are decoded, or interpreted in different ways depending on an individual's cultural background, economic standing, and personal experiences. In contrast to other media theories that disempower audiences, Hall proposed that audience members can play an active role in decoding messages as they rely on their own social contexts, and might be capable of changing messages themselves through collective action. In simpler terms, encoding/decoding is the translation of a message that is easily understood. When you decode a message, you extract the meaning of that message in ways that make sense to you. Decoding has both verbal and non-verbal forms of communication: Decoding behavior without using words means observing body language and its associated emotions. For example, some body language signs for when someone is upset, angry, or stressed would be a use of excessive hand/arm movements, red in the face, crying, and even sometimes silence. Sometimes when someone is trying to get a message across to someone, the message can be interpreted differently from person to person. Decoding is all about the understanding of what someone already knows, based on the information given throughout the message being received. Whether there is a large audience or exchanging a message to one person, decoding is the process of obtaining, absorbing, understanding, and sometimes using the information that was given throughout a verbal or non-verbal message.\" ~ Wikipedia (https://en.wikipedia.org/wiki/Encoding/decoding_model_of_communication)\n",
    "\n",
    "[![chatbot](img/seq2seq.png)](img/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:56<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# train the model for 40% of the length for number of features\n",
    "for a in tqdm(range(0, n_features//10*4)):\n",
    "    for n in range(0, len(padded_q_docs)):\n",
    "        # transform xy\n",
    "        X,y = transform_xy(padded_q_docs[n], padded_a_docs[n], n_features)\n",
    "        \n",
    "        # fit model for one epoch on this sequence\n",
    "        model.fit(X, y, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It took Monty about a minute to learn...\n",
    "\n",
    "[![chatbot](img/study.jpg)](img/study.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set #12\n",
      "Question Array: [98, 54, 27, 108, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : what is your name                 \n",
      "\n",
      "Expected Response Array: [64, 96, 79, 61, 118, 61, 100, 58, 45, 0, 0, 0] \n",
      "Expected Response: i cannot tell you because you are a stranger       \n",
      "\n",
      "Predicted Response Array: [64, 96, 79, 61, 118, 61, 100, 58, 45, 0, 0, 0] \n",
      "Predicted Response: i cannot tell you because you are a stranger       \n",
      "\n",
      "Set #13\n",
      "Question Array: [52, 102, 100, 61, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : how old are you                 \n",
      "\n",
      "Expected Response Array: [26, 54, 106, 2, 61, 87, 58, 129, 0, 0, 0, 0] \n",
      "Expected Response: that is not something you ask a lady         \n",
      "\n",
      "Predicted Response Array: [26, 54, 106, 2, 61, 87, 58, 129, 0, 0, 0, 0] \n",
      "Predicted Response: that is not something you ask a lady         \n",
      "\n",
      "Set #14\n",
      "Question Array: [98, 25, 61, 25, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : what do you do                 \n",
      "\n",
      "Expected Response Array: [17, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: professional chatbox                     \n",
      "\n",
      "Predicted Response Array: [17, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: professional chatbox                     \n",
      "\n",
      "Total Training Accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "# print 3 sets of questions, expected response and predicted response\n",
    "for n in range(12, 15):\n",
    "    X,y = transform_xy(padded_q_docs[n], padded_a_docs[n], n_features)\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    print('Set #{}'.format(n))\n",
    "    print('Question Array:', one_hot_decode(X[0]),'\\nQuestion :', array_to_string(one_hot_decode(X[0]), t_df), '\\n')\n",
    "    print('Expected Response Array:', one_hot_decode(y[0]), '\\nExpected Response:', array_to_string(one_hot_decode(y[0]), t_df), '\\n')\n",
    "    print('Predicted Response Array:', one_hot_decode(yhat[0]), '\\nPredicted Response:', array_to_string(one_hot_decode(yhat[0]), t_df), '\\n')\n",
    "\n",
    "# print accuracy of model\n",
    "total, correct = len(padded_q_docs), 0\n",
    "for n in range(total):\n",
    "    X,y = transform_xy(padded_q_docs[n], padded_a_docs[n], n_features)\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    if array_equal(one_hot_decode(y[0]), one_hot_decode(yhat[0])):\n",
    "        correct += 1\n",
    "print('Total Training Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set #0\n",
      "Question Array: [82, 91, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : hello there                     \n",
      "\n",
      "Expected Response Array: [22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: hi                       \n",
      "\n",
      "Predicted Response Array: [22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: hi                       \n",
      "\n",
      "Set #1\n",
      "Question Array: [52, 54, 6, 66, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : how is it going                 \n",
      "\n",
      "Expected Response Array: [84, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: great                       \n",
      "\n",
      "Predicted Response Array: [84, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: great                       \n",
      "\n",
      "Set #2\n",
      "Question Array: [52, 100, 61, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : how are you                   \n",
      "\n",
      "Expected Response Array: [77, 61, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: good you                     \n",
      "\n",
      "Predicted Response Array: [77, 61, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: good you                     \n",
      "\n",
      "Set #3\n",
      "Question Array: [103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : bye                       \n",
      "\n",
      "Expected Response Array: [88, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: goodbye                       \n",
      "\n",
      "Predicted Response Array: [88, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: goodbye                       \n",
      "\n",
      "Set #4\n",
      "Question Array: [15, 61, 79, 90, 27, 108, 0, 0, 0, 0, 0, 0] \n",
      "Question : can you tell me your name             \n",
      "\n",
      "Expected Response Array: [64, 96, 79, 61, 118, 61, 100, 58, 45, 0, 0, 0] \n",
      "Expected Response: i cannot tell you because you are a stranger       \n",
      "\n",
      "Predicted Response Array: [64, 96, 79, 61, 118, 61, 100, 58, 45, 0, 0, 0] \n",
      "Predicted Response: i cannot tell you because you are a stranger       \n",
      "\n",
      "Set #5\n",
      "Question Array: [46, 58, 130, 116, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : youre a stupid robot                 \n",
      "\n",
      "Expected Response Array: [3, 62, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: well thats rude                   \n",
      "\n",
      "Predicted Response Array: [3, 62, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: well thats rude                   \n",
      "\n",
      "Set #6\n",
      "Question Array: [15, 61, 79, 90, 2, 62, 4, 0, 0, 0, 0, 0] \n",
      "Question : can you tell me something thats interesting           \n",
      "\n",
      "Expected Response Array: [2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: something interesting                     \n",
      "\n",
      "Predicted Response Array: [2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: something interesting                     \n",
      "\n",
      "Set #7\n",
      "Question Array: [98, 110, 25, 61, 9, 117, 0, 0, 0, 0, 0, 0] \n",
      "Question : what sport do you like to             \n",
      "\n",
      "Expected Response Array: [105, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: basketball                       \n",
      "\n",
      "Predicted Response Array: [17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: professional                       \n",
      "\n",
      "Set #8\n",
      "Question Array: [98, 0, 134, 110, 25, 61, 122, 11, 0, 0, 0, 0] \n",
      "Question : what   of sport do you enjoy playing         \n",
      "\n",
      "Expected Response Array: [112, 36, 65, 135, 59, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: baseball sometimes football and hockey               \n",
      "\n",
      "Predicted Response Array: [112, 36, 65, 135, 59, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: baseball sometimes football and hockey               \n",
      "\n",
      "Set #9\n",
      "Question Array: [98, 54, 27, 108, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : what is your name                 \n",
      "\n",
      "Expected Response Array: [64, 96, 79, 61, 118, 61, 100, 58, 45, 0, 0, 0] \n",
      "Expected Response: i cannot tell you because you are a stranger       \n",
      "\n",
      "Predicted Response Array: [64, 96, 79, 61, 118, 61, 100, 58, 45, 0, 0, 0] \n",
      "Predicted Response: i cannot tell you because you are a stranger       \n",
      "\n",
      "Set #10\n",
      "Question Array: [27, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : your name                     \n",
      "\n",
      "Expected Response Array: [64, 96, 79, 61, 118, 61, 100, 58, 45, 0, 0, 0] \n",
      "Expected Response: i cannot tell you because you are a stranger       \n",
      "\n",
      "Predicted Response Array: [64, 96, 79, 61, 118, 61, 100, 58, 45, 0, 0, 0] \n",
      "Predicted Response: i cannot tell you because you are a stranger       \n",
      "\n",
      "Set #11\n",
      "Question Array: [75, 86, 117, 123, 95, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : no need to be sarcastic               \n",
      "\n",
      "Expected Response Array: [23, 90, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: who me                     \n",
      "\n",
      "Predicted Response Array: [17, 126, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: professional thank                     \n",
      "\n",
      "Set #12\n",
      "Question Array: [46, 58, 114, 116, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : youre a funny robot                 \n",
      "\n",
      "Expected Response Array: [76, 126, 61, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: why thank you                   \n",
      "\n",
      "Predicted Response Array: [75, 86, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: no need                     \n",
      "\n",
      "Set #13\n",
      "Question Array: [0, 58, 33, 131, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question :   a favorite song                 \n",
      "\n",
      "Expected Response Array: [50, 60, 1, 104, 10, 107, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: all the single ladies by beyonce             \n",
      "\n",
      "Predicted Response Array: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response:                         \n",
      "\n",
      "Set #14\n",
      "Question Array: [100, 61, 58, 0, 134, 83, 0, 0, 0, 0, 0, 0] \n",
      "Question : are you a   of ai             \n",
      "\n",
      "Expected Response Array: [75, 64, 25, 106, 67, 41, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: no i do not think so             \n",
      "\n",
      "Predicted Response Array: [75, 64, 25, 106, 67, 41, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: no i do not think so             \n",
      "\n",
      "Set #15\n",
      "Question Array: [52, 102, 100, 61, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : how old are you                 \n",
      "\n",
      "Expected Response Array: [26, 54, 106, 2, 61, 87, 58, 129, 0, 0, 0, 0] \n",
      "Expected Response: that is not something you ask a lady         \n",
      "\n",
      "Predicted Response Array: [26, 54, 106, 2, 61, 87, 58, 129, 0, 0, 0, 0] \n",
      "Predicted Response: that is not something you ask a lady         \n",
      "\n",
      "Set #16\n",
      "Question Array: [100, 61, 58, 0, 134, 83, 0, 0, 0, 0, 0, 0] \n",
      "Question : are you a   of ai             \n",
      "\n",
      "Expected Response Array: [75, 64, 25, 106, 67, 41, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: no i do not think so             \n",
      "\n",
      "Predicted Response Array: [75, 64, 25, 106, 67, 41, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: no i do not think so             \n",
      "\n",
      "Set #17\n",
      "Question Array: [46, 58, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : youre a liar                   \n",
      "\n",
      "Expected Response Array: [75, 86, 117, 123, 109, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: no need to be sensitive               \n",
      "\n",
      "Predicted Response Array: [75, 86, 117, 123, 109, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: no need to be sensitive               \n",
      "\n",
      "Set #18\n",
      "Question Array: [25, 61, 0, 58, 33, 111, 0, 0, 0, 0, 0, 0] \n",
      "Question : do you   a favorite color             \n",
      "\n",
      "Expected Response Array: [124, 58, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Expected Response: its a secret                   \n",
      "\n",
      "Predicted Response Array: [78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: hell                       \n",
      "\n",
      "Set #19\n",
      "Question Array: [60, 72, 134, 5, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "Question : the purpose of life                 \n",
      "\n",
      "Expected Response Array: [64, 85, 57, 62, 127, 42, 12, 90, 0, 0, 0, 0] \n",
      "Expected Response: i dont know thats too deep for me         \n",
      "\n",
      "Predicted Response Array: [64, 54, 79, 2, 38, 0, 0, 0, 0, 0, 0, 0] \n",
      "Predicted Response: i is tell something should               \n",
      "\n",
      "Total Test Accuracy: 70.00% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_q_list, test_q_as_array = word_to_array(test_df.question, t_df)\n",
    "test_a_list, test_a_as_array = word_to_array(test_df.answer, t_df)\n",
    "\n",
    "test_padded_q_docs = pad_sequences(test_q_as_array, maxlen=max_length, padding='post')\n",
    "test_padded_a_docs = pad_sequences(test_a_as_array, maxlen=max_length, padding='post')\n",
    "\n",
    "# print 3 sets of questions, expected response and predicted response\n",
    "for n in range(len(test_padded_q_docs)):\n",
    "    X,y = transform_xy(test_padded_q_docs[n], test_padded_a_docs[n], n_features)\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    print('Set #{}'.format(n))\n",
    "    print('Question Array:', one_hot_decode(X[0]), '\\nQuestion :', array_to_string(one_hot_decode(X[0]), t_df), '\\n')\n",
    "    print('Expected Response Array:', one_hot_decode(y[0]), '\\nExpected Response:', array_to_string(one_hot_decode(y[0]), t_df), '\\n')\n",
    "    print('Predicted Response Array:', one_hot_decode(yhat[0]), '\\nPredicted Response:', array_to_string(one_hot_decode(yhat[0]), t_df), '\\n')\n",
    "\n",
    "# print accuracy of model\n",
    "total, correct = len(test_padded_q_docs), 0\n",
    "for n in range(total):\n",
    "    X,y = transform_xy(test_padded_q_docs[n], test_padded_a_docs[n], n_features)\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    if array_equal(one_hot_decode(y[0]), one_hot_decode(yhat[0])):\n",
    "        correct += 1\n",
    "print('Total Test Accuracy: %.2f%%' % (float(correct)/float(total)*100.0), '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  hello \n",
      "Monty:  hi                      \n",
      "User:  how goes it? \n",
      "Monty:  great                      \n",
      "User:  what do you do for work? \n",
      "Monty:  talking to interesting people someone thats not you        \n",
      "User:  can you tell me your name? \n",
      "Monty:  i cannot tell you because you are a stranger      \n",
      "User:  you're a mean robot \n",
      "Monty:  hahahahaha                      \n",
      "User:  bye \n",
      "Monty:  goodbye                      \n"
     ]
    }
   ],
   "source": [
    "# create sentences that are not in the list of questions and answers list\n",
    "sent0 = \"hello\"\n",
    "sent1 = \"how goes it?\"\n",
    "sent2 = \"what do you do for work?\"\n",
    "sent3 = \"can you tell me your name?\"\n",
    "sent4 = \"you're a mean robot\"\n",
    "sent5 = \"bye\"\n",
    "\n",
    "for n in range(0, 6):\n",
    "    print('User: ', eval('sent'+str(n)),\n",
    "          '\\nMonty: ', get_response(eval('sent'+str(n)), t_df, max_length, n_features, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![chatbot](img/thankyou.jpg)](img/thankyou.jpg)\n",
    "# ... for chatting with Monty\n",
    "<br/><br/><br/>\n",
    "# Works Cited\n",
    "Morgan, Blake. Forbes. 03 21, 2017. https://www.forbes.com/sites/blakemorgan/2017/03/21/how-chatbots-will-transform-customer-experience-an-infographic/#646faa017fb4 (accessed 03 22, 2018).\n",
    "\n",
    "Nielsen, Jakob. Nielsen Norman Group. 09 12, 2011. https://www.nngroup.com/articles/how-long-do-users-stay-on-web-pages/ (accessed 03 22, 2018)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
